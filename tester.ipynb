{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#import numpy as np\n",
    "#from PIL import Image\n",
    "#import tflite_runtime.interpreter as tflite\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "edgetpu='0' # make it '1' if Coral Accelerator is attached and use model with 'edgetpu' name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====custom model and label files==================\n",
    "'''\n",
    "model_dir = 'models/custom'\n",
    "\n",
    "model = 'custom_detection_model.tflite'\n",
    "#model = 'custom_detection_model_edgetpu.tflite'\n",
    "\n",
    "label = 'custom_labels.txt'\n",
    "'''\n",
    "#=================================================\n",
    "\n",
    "#====pretrained model and label files==================\n",
    "\n",
    "model_dir = 'models/pretrained'\n",
    "\n",
    "model='mobilenet_ssd_v2_coco_quant_postprocess.tflite'\n",
    "#model='mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite'\n",
    "\n",
    "#model='efficientdet_lite0.tflite'\n",
    "#model='efficientdet_lite0_edgetpu.tflite'\n",
    "\n",
    "label = 'coco_labels.txt'\n",
    "\n",
    "#=================================================\n",
    "\n",
    "model_path=os.path.join(model_dir,model)\n",
    "label_path=os.path.join(model_dir,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------object detection--------------------------------------------------\n",
    "def detect_objects(interpreter, image, score_threshold=0.3, top_k=6):\n",
    "    \"\"\"Returns list of detected objects.\"\"\"\n",
    "    set_input_tensor(interpreter, image)\n",
    "    #interpreter.invoke()\n",
    "    invoke_interpreter(interpreter)\n",
    "    \n",
    "    global model_dir\n",
    "    if (model_dir=='models/pretrained'):\n",
    "      # for pre-trained models\n",
    "      boxes = get_output_tensor(interpreter, 0)\n",
    "      class_ids = get_output_tensor(interpreter, 1)\n",
    "      scores = get_output_tensor(interpreter, 2)\n",
    "      count = int(get_output_tensor(interpreter, 3))\n",
    "    else:\n",
    "      # for custom models made by Model Maker \n",
    "      scores = get_output_tensor(interpreter, 0)\n",
    "      boxes = get_output_tensor(interpreter, 1)\n",
    "      count = int(get_output_tensor(interpreter, 2))\n",
    "      class_ids = get_output_tensor(interpreter, 3)\n",
    "  \n",
    "    \n",
    "    def make(i):\n",
    "        ymin, xmin, ymax, xmax = boxes[i]\n",
    "        return Object(\n",
    "            id=int(class_ids[i]),\n",
    "            score=scores[i],\n",
    "            bbox=BBox(xmin=np.maximum(0.0, xmin),\n",
    "                      ymin=np.maximum(0.0, ymin),\n",
    "                      xmax=np.minimum(1.0, xmax),\n",
    "                      ymax=np.minimum(1.0, ymax)))\n",
    "\n",
    "    return [make(i) for i in range(top_k) if scores[i] >= score_threshold]\n",
    "\n",
    "\n",
    "import collections\n",
    "Object = collections.namedtuple('Object', ['id', 'score', 'bbox'])\n",
    "\n",
    "class BBox(collections.namedtuple('BBox', ['xmin', 'ymin', 'xmax', 'ymax'])):\n",
    "    \"\"\"Bounding box.\n",
    "    Represents a rectangle which sides are either vertical or horizontal, parallel\n",
    "    to the x or y axis.\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "#--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Loading Labels----------------------------------------------------\n",
    "import re\n",
    "def load_labels(path):\n",
    "  \"\"\"Loads the labels file. Supports files with or without index numbers.\"\"\"\n",
    "  \n",
    "  with open(path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    labels = {}\n",
    "    for row_number, content in enumerate(lines):\n",
    "      pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n",
    "      if len(pair) == 2 and pair[0].strip().isdigit():\n",
    "        labels[int(pair[0])] = pair[1].strip()\n",
    "      else:\n",
    "        labels[row_number] = pair[0].strip()\n",
    "  return labels\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Making Interpreter---------------------------------------------------------\n",
    "import platform\n",
    "\n",
    "EDGETPU_SHARED_LIB = {\n",
    "  'Linux': 'libedgetpu.so.1',\n",
    "  'Darwin': 'libedgetpu.1.dylib',\n",
    "  'Windows': 'edgetpu.dll'\n",
    "}[platform.system()]\n",
    "      \n",
    "def make_interpreter(path, edgetpu):\n",
    "    print (path,edgetpu)\n",
    "    if(edgetpu=='0'):\n",
    "        interpreter = tflite.Interpreter(model_path=path)\n",
    "    else:\n",
    "      path, *device = path.split('@')\n",
    "      interpreter = tflite.Interpreter(model_path=path,experimental_delegates=[tflite.load_delegate(EDGETPU_SHARED_LIB,{'device': device[0]} if device else {})])\n",
    "        \n",
    "        \n",
    "    print('Loading Model: {} '.format(path))\n",
    "    \n",
    "    return interpreter\n",
    "\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'model.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Load TFLite model and allocate tensors.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m interpreter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlite\u001b[39m.\u001b[39;49mInterpreter(model_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel.tflite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Get input and output tensors.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m input_details \u001b[39m=\u001b[39m interpreter\u001b[39m.\u001b[39mget_input_details()\n",
      "File \u001b[1;32mc:\\Users\\Hasan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:455\u001b[0m, in \u001b[0;36mInterpreter.__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001b[0m\n\u001b[0;32m    448\u001b[0m custom_op_registerers_by_name \u001b[39m=\u001b[39m [\n\u001b[0;32m    449\u001b[0m     x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_custom_op_registerers \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    450\u001b[0m ]\n\u001b[0;32m    451\u001b[0m custom_op_registerers_by_func \u001b[39m=\u001b[39m [\n\u001b[0;32m    452\u001b[0m     x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_custom_op_registerers \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    453\u001b[0m ]\n\u001b[0;32m    454\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpreter \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 455\u001b[0m     _interpreter_wrapper\u001b[39m.\u001b[39;49mCreateWrapperFromFile(\n\u001b[0;32m    456\u001b[0m         model_path, op_resolver_id, custom_op_registerers_by_name,\n\u001b[0;32m    457\u001b[0m         custom_op_registerers_by_func, experimental_preserve_all_tensors))\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpreter:\n\u001b[0;32m    459\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mFailed to open \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model_path))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not open 'model.tflite'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import pathlib\n",
    "import sys\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "# input details\n",
    "print(input_details)\n",
    "# output details\n",
    "print(output_details)\n",
    "interpreter.allocate_tensors()\n",
    "for file in pathlib.Path(sys.argv[1]).iterdir():\n",
    "    # read and resize the image\n",
    "    img = cv.imread(r\"{}\".format(file.resolve()))\n",
    "    new_img = cv.resize(img, (224, 224))\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], [new_img])\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    if (output_data[0][0] > 200):\n",
    "        print(\"file {} -> indosiar_ads\".format(file.stem))\n",
    "    elif (output_data[0][1] > 200):\n",
    "        print(\"file {} -> indosiar\".format(file.stem))\n",
    "    elif (output_data[0][2] > 200):\n",
    "        print(\"file {} -> sctv\".format(file.stem))\n",
    "    elif (output_data[0][3] > 200):\n",
    "        print(\"file {} -> sctv_ads\".format(file.stem))\n",
    "    else:\n",
    "        print(\"file {} -> unknown\".format(file.stem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4323cec2d52b922c9f7bbe1804da129109550f4257a94c7360d37c119722165e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
